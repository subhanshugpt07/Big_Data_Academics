{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mApplications\u001b[m\u001b[m/              \u001b[35metc\u001b[m\u001b[m@\r\n",
      "\u001b[34mLibrary\u001b[m\u001b[m/                   \u001b[34mhome\u001b[m\u001b[m/\r\n",
      "\u001b[34mNetwork\u001b[m\u001b[m/                   installer.failurerequests\r\n",
      "\u001b[31mPostInstall.sh\u001b[m\u001b[m*            \u001b[34mnet\u001b[m\u001b[m/\r\n",
      "\u001b[34mSystem\u001b[m\u001b[m/                    \u001b[34mopt\u001b[m\u001b[m/\r\n",
      "\u001b[34mUsers\u001b[m\u001b[m/                     \u001b[34mprivate\u001b[m\u001b[m/\r\n",
      "\u001b[30m\u001b[42mVolumes\u001b[m\u001b[m/                   \u001b[34msbin\u001b[m\u001b[m/\r\n",
      "\u001b[34mbin\u001b[m\u001b[m/                       \u001b[35mtmp\u001b[m\u001b[m@\r\n",
      "\u001b[34mcores\u001b[m\u001b[m/                     \u001b[34musr\u001b[m\u001b[m/\r\n",
      "\u001b[34mdev\u001b[m\u001b[m/                       \u001b[35mvar\u001b[m\u001b[m@\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.context.SparkContext at 0x10f646550>"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'# Apache Spark',\n",
       " u'',\n",
       " u'Spark is a fast and general cluster computing system for Big Data. It provides',\n",
       " u'high-level APIs in Scala, Java, Python, and R, and an optimized engine that',\n",
       " u'supports general computation graphs for data analysis. It also supports a',\n",
       " u'rich set of higher-level tools including Spark SQL for SQL and DataFrames,',\n",
       " u'MLlib for machine learning, GraphX for graph processing,',\n",
       " u'and Spark Streaming for stream processing.',\n",
       " u'',\n",
       " u'<http://spark.apache.org/>']"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = sc.textFile('/Users/arnavsomani/spark-2.1.0-bin-hadoop2.7/README.md')\n",
    "testRdd = sc.parallelize([1,2,3,4,5])\n",
    "rdd.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testRdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wc = rdd.flatMap(lambda line: line.split()) \\\n",
    "           .map(lambda x:(x.lower(),1)) \\\n",
    "           .groupByKey() \\\n",
    "           .mapValues(lambda values: sum(values))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'when', 1), (u'alternatively,', 1)]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'when', 1), (u'alternatively,', 1)]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc = rdd.flatMap(lambda line: line.split()) \\\n",
    "           .map(lambda x:(x.lower(),1)) \\\n",
    "           .reduceByKey(lambda x,y: x+y)\n",
    "    \n",
    "\n",
    "wc.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(u'the', 25), (u'to', 19), (u'spark', 16)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wc.top(3,key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'/'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SAT_FN = 'SAT_Results.csv'\n",
    "HSD_FN = 'DOE_High_School_Directory_2014-2015.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1 = spark.read \\\n",
    "           .format('com.databricks.spark.csv')\\\n",
    "           .option('header','true') \\\n",
    "           .option('inferSchema','true') \\\n",
    "           .option('parserLib','UNIVOCITY') \\\n",
    "           .load(HSD_FN) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DBN,SCHOOL NAME,Num of SAT Test Takers,SAT Critical Reading Avg. Score,SAT Math Avg. Score,SAT Writing Avg. Score',\n",
       " '02M047,47 THE AMERICAN SIGN LANGUAGE AND ENGLISH SECONDARY SCHOOL,16,395,400,387']"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat = sc.textFile(SAT_FN, use_unicode=False).cache()\n",
    "#b = sat.collect()\n",
    "#b\n",
    "sat.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DBN,SCHOOL NAME,Num of SAT Test Takers,SAT Critical Reading Avg. Score,SAT Math Avg. Score,SAT Writing Avg. Score',\n",
       " '02M047,47 THE AMERICAN SIGN LANGUAGE AND ENGLISH SECONDARY SCHOOL,16,395,400,387']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sat.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 'DBN'),\n",
       " (1, 'SCHOOL NAME'),\n",
       " (2, 'Num of SAT Test Takers'),\n",
       " (3, 'SAT Critical Reading Avg. Score'),\n",
       " (4, 'SAT Math Avg. Score'),\n",
       " (5, 'SAT Writing Avg. Score')]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(enumerate(sat.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sat = sat.repartition(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sat.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#sat.filter(lambda x: not x.startwith('DBN,SCHOOL')).take(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractScores(partId,list_of_records):\n",
    "    if partId==0:\n",
    "        list_of_records.next()\n",
    "    import csv\n",
    "    reader = csv.reader(list_of_records)\n",
    "    for row in reader:\n",
    "        if row[2]!='s':\n",
    "            (dbn,takers,score) = (row[0],int(row[2]),int(row[4]))\n",
    "            yield dbn,(score*takers,takers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "satScores = sat.mapPartitionsWithIndex(extractScores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#a = satScores.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "schools = sc.textFile(HSD_FN, use_unicode=False).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#list(enumerate(school.first().split(',')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extractSchools(partId,list_of_records):\n",
    "    if partId==0:\n",
    "        list_of_records.next()\n",
    "    import csv\n",
    "    reader = csv.reader(list_of_records)\n",
    "    for row in reader:\n",
    "        if len(row)==58 and row[17].isdigit():\n",
    "            (dbn,boro,total_students) = (row[0],row[2],int(row[17]))\n",
    "            if total_students>500:\n",
    "                yield(dbn,boro)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "largeSchools = schools.mapPartitionsWithIndex(extractSchools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('01M450', 'Manhattan'),\n",
       " ('01M539', 'Manhattan'),\n",
       " ('01M696', 'Manhattan'),\n",
       " ('02M374', 'Manhattan'),\n",
       " ('02M400', 'Manhattan'),\n",
       " ('02M408', 'Manhattan'),\n",
       " ('02M412', 'Manhattan'),\n",
       " ('02M413', 'Manhattan'),\n",
       " ('02M416', 'Manhattan'),\n",
       " ('02M418', 'Manhattan')]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "largeSchools.take(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = largeSchools.join(satScores).values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bronx', (23069, 59)),\n",
       " ('Staten Island', (52216, 107)),\n",
       " ('Bronx', (16317, 49))]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.take(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Bronx', 470),\n",
       " ('Manhattan', 514),\n",
       " ('Brooklyn', 487),\n",
       " ('Staten Island', 477),\n",
       " ('Queens', 474)]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores.reduceByKey(lambda x,y: (x[0]+y[0], x[1]+y[1])) \\\n",
    "    .mapValues(lambda x: x[0]/x[1]) \\\n",
    "    .collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
